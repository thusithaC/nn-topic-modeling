{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.mongodb.spark:mongo-spark-connector_2.12:3.0.0 pyspark-shell'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"pyspark-notebook\")\\\n",
    "    .master(\"spark://spark-master:7077\")\\\n",
    "    .config(\"spark.driver.memory\", \"4G\")\\\n",
    "    .config(\"spark.executor.memory\", \"7500m\")\\\n",
    "    .config(\"spark.mongodb.input.uri\", \"mongodb://mongo_docker_mongodb-service_1:27017/twitter.rawTweets\") \\\n",
    "    .config(\"spark.mongodb.output.uri\", \"mongodb://mongo_docker_mongodb-service_1:27017/twitter\")\\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"1000\")\\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = spark.read.format(\"mongo\").load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df_raw.sample(withReplacement=False, fraction=0.001)\n",
    "#text = df.select(\"data.text\")\n",
    "text = df_raw.select(\"data.text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType\n",
    "from langdetect import detect \n",
    "\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation \n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "STOP_WORDS = set(stopwords.words(\"english\") + list(punctuation) + ['AT_USER','URL', 'rt'])\n",
    "EMOJI_PATTERN = re.compile(\n",
    "    \"[\"\n",
    "    \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "    \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "    \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "    \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "    \"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "    \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "    \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "    \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "    \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "    \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "    \"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "    \"\\U000024C2-\\U0001F251\" \n",
    "    \"]+\")\n",
    "    \n",
    "def process_tweet(tweet):\n",
    "    if tweet is None:\n",
    "        return \"\"\n",
    "    tweet = str(tweet).lower() # convert text to lower-case\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'URL', tweet) # remove URLs\n",
    "    tweet = re.sub('@[^\\s]+', '', tweet) # remove usernames\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet) # remove the # in #hashtag\n",
    "    tweet = re.sub(r':[^\\s]+', r'', tweet) # remove emoticons starting with :\n",
    "    tweet = re.sub(EMOJI_PATTERN, r'', tweet) # remove emoticons\n",
    "    tweet =  re.sub(r'[^\\w\\s]','', tweet)\n",
    "    tweet = word_tokenize(tweet) # remove repeated characters (helloooooooo into hello)\n",
    "    return \" \".join([word for word in tweet if word not in STOP_WORDS]).strip()\n",
    "\n",
    "def lang_detect(text):\n",
    "    try:\n",
    "        lang = detect(text)\n",
    "    except:\n",
    "        lang = \"\"\n",
    "    return lang\n",
    "\n",
    "def sentence_len(text):\n",
    "    return len(text.split())\n",
    "\n",
    "u_lang_detect = udf(lang_detect, StringType())\n",
    "u_process_tweet = udf(process_tweet, StringType())\n",
    "u_sentence_len = udf(sentence_len, IntegerType())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_with_language = text.withColumn('processed', u_process_tweet('text')).withColumn('lang', u_lang_detect('processed')).withColumn('length', u_sentence_len('processed'))\n",
    "text_filtered = text_with_language.filter(\"lang  == 'en'\").filter(\"length > 8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_filtered.write.format(\"mongo\").mode(\"append\").option(\"collection\", \"processedTweetsEN\").save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
